---
title: "Assignment - Final Project"
author: "Abduvosid Malikov"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---

## Introduction

This is the Final Project for `Web Scraping with R` course. As a source,  [vox](https://www.vox.com/search?page=1&q=Biden) news website was scraped with the keyword^[search term used: 'Biden'.]. 

It is better to use boxes in this function: get_one_page_from_vox
and apply a function for the boxes.

You could also show your df result in the html.

## First function

The function `get_one_page_from_vox()` accepts url as an argument. Then it downloads information from that passed url to dataframe 

```{r, warning=FALSE, message=FALSE}

library(rvest)
library(data.table)

# a function which downloads information from the website to dataframe
get_one_page_from_vox <- function(arg_url) {
  
  # to get a web page, pass URL to read_html 
  file_html <- read_html(arg_url)
  
  # save it as html document
  write_html(file_html, 'html_file.html')
  
  headings <- 
    file_html %>% 
    html_nodes('.c-entry-box--compact__title') %>% 
    html_text()
  
  post_links <- 
    file_html %>% 
    html_nodes('.c-entry-box--compact__title') %>% 
    html_nodes('a') %>%
    html_attr('href')
  
  posted_date <- 
    file_html %>% 
    html_nodes('time') %>% 
    html_text(trim = TRUE)
  
  author <- 
    file_html %>% 
    html_nodes('.c-byline__item') %>% 
    html_text(trim = TRUE) 
  
  authors <- c()
  
  for(x in seq(1,length(author),3)) {
    authors <- c(authors, author[x]) 
  }
  
  # to create a dataframe
  df <- data.frame('headings' = headings, 'post_link' = post_links, 'date' = posted_date, 'author' = authors)  
  
  return(df)
}
```

### Testing the function

``` {r, warning=FALSE, message=FALSE}

# test the function
test_df <- get_one_page_from_vox('https://www.vox.com/search?page=1&q=Biden')

# generate the URLs
test_urls <- paste0('https://www.vox.com/search?page=', 1:5, '&q=Biden' )

#apply a function to a list
df_list <- lapply(test_urls, get_one_page_from_vox)

#create a data.table object of the list of data.frames
df <- rbindlist(df_list)
```

## Second function

The function `get_vox_pages()` requires two arguments. First a keyword then a number of pages to download.
Inside the function, the links are created and `get_one_page_from_vox()` function is applied to the links that are created.
It also creates the dataframe, saves it into csv and rds objects.

``` {r, warning=FALSE, message=FALSE}
library(readr)

get_vox_pages <- function(keyword, no_pages){
  main_url <- 'https://www.vox.com/search?page='

  # generate the URLs
  links <- paste0(main_url, 1:no_pages, '&q=', keyword)
  return_df <- rbindlist(lapply(links, get_one_page_from_vox))
  
  write_csv(return_df, 'data/result.csv')
  saveRDS(return_df, file = 'data/rdsfile.rds')

  
  return(return_df)
}

```

### Testing the function

```{r, warning=FALSE, message=FALSE}

# check the function
returned_df <- get_vox_pages(keyword = 'Biden', 6)
```
